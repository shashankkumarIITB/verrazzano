// Copyright (c) 2020, 2022, Oracle and/or its affiliates.
// Licensed under the Universal Permissive License v 1.0 as shown at https://oss.oracle.com/licenses/upl.

// This pipeline is configured to test Verrazzano using OLCNE environment
// -> Setup Kubernetes in OLCNE environment
// -> Setup persistent storage for Verrazzano 
// -> Create OCI Load Balancers
// -> Setup DNS Zone with the records
// -> Install Verrazzano 
// -> Deploys Verrazzano test applications 
// -> Runs validations 
// -> Undeploy the apps
// -> Uninstall Verrazzano
// -> Cleanup resources

def testEnvironments = ["olcne"]
def agentLabel = env.JOB_NAME.contains('-olcne') ? "" : env.JOB_NAME.contains('master') ? "phxlarge" : "VM.Standard2.8"
// pulling "ap-*" from the test regions given discovery of image pull issues
def availableRegions = ["us-ashburn-1"]
def availableDomains = ["hXgQ:US-ASHBURN-AD-1"]
def kubernetesVersions = [ "v1.22.5", "v1.21.5", "v1.20.8" ]
def olcneVersions = [ "1.5", "1.4", "1.3"]
def osVersions = ['8', '7']
def dnsZoneSubdomainName = UUID.randomUUID().toString().substring(0,6).replace('-','')
def dnsScopes = ['GLOBAL', 'PRIVATE']
def EFFECTIVE_DUMP_K8S_CLUSTER_ON_SUCCESS = false
def keepOLCNEClusterOnFailure = false

pipeline {
    options {
        skipDefaultCheckout true
        copyArtifactPermission('*');
        timestamps ()
    }

    agent {
        docker {
            image "${RUNNER_DOCKER_IMAGE}"
            args "${RUNNER_DOCKER_ARGS} --cap-add=NET_ADMIN"
            registryUrl "${RUNNER_DOCKER_REGISTRY_URL}"
            label "$agentLabel"
        }
    }

    parameters {
        // Cluster type
        choice (
            name: 'TEST_ENV',
            description: 'Verrazzano Test Environment', 
            choices: testEnvironments)
        choice (
            name: 'K8S_VERSION',
            description: 'Kubernetes Version for the cluster', 
            choices: kubernetesVersions)
        // OLCNE configuration
        choice (
            name: 'OLCNE_VERSION',
            description: 'OLCNE Version', 
            choices: olcneVersions)
        choice (
            name: 'OLCNE_CLUSTER_REGION',
            description: 'OCI region to launch OLCNE clusters in.',
            choices: availableRegions)
        choice (
            name: 'OLCNE_CLUSTER_AVAILABILITY_DOMAIN',
            description: 'Availability domain for the cluster region.',
            choices: availableDomains)
        string (
            name: "CONTROL_PLANE_NODE_COUNT",
            defaultValue: '1',
            description: 'Number of OLCNE control plane nodes',
            trim: true)
        string (
            name: "WORKER_NODE_COUNT",
            defaultValue: '3',
            description: 'Number of OLCNE worker nodes',
            trim: true)
        choice (
            name: "OLCNE_OS_VERSION",
            description: 'OracleLinux OS version OLCNE nodes',
            choices: osVersions)
        string (
            name: "OLCNE_ENVIRONMENT_NAME",
            defaultValue: 'olcne-environment',
            description: 'Name of the OLCNE environment',
            trim: true)
        string (
            name: "OLCNE_KUBERNETES_NAME",
            defaultValue: 'olcne-cluster',
            description: 'Name of the OLCNE cluster',
            trim: true)
        choice(
            name: 'OCI_DNS_SCOPE',
            description: 'Specifies OCI DNS scope. Default: GLOBAL', 
            choices: dnsScopes)
        // TODO: To be removed, fetch OLCNE_TERRAFORM_GIT_URL from credentials
        string (
            name: "OLCNE_TERRAFORM_GIT_URL",
            defaultValue: '',
            description: 'terraform-oci-olcne Gitlab URL',
            trim: true)
        string (
            name: "INSTALL_PROFILE",
            defaultValue: 'dev',
            description: 'Verrazzano install profile name',
            trim: true)
        string (
            name: 'VERRAZZANO_OPERATOR_IMAGE', 
            description: 'Verrazzano platform operator image name (within ghcr.io/verrazzano repo)', 
            defaultValue: 'NONE', 
            trim: true)
        string (
            name: 'GIT_COMMIT_TO_USE',
            description: 'This is the full git commit hash from the source build to be used for all jobs',
            defaultValue: 'NONE',
            trim: true)
        string (name: 'CONSOLE_REPO_BRANCH',
                defaultValue: '',
                description: 'The branch to check out after cloning the console repository.',
                trim: true)
        booleanParam (
            name: 'DUMP_K8S_CLUSTER_ON_SUCCESS', 
            description: 'Whether to dump k8s cluster on success (off by default can be useful to capture for comparing to failed cluster)', 
            defaultValue: false)
        booleanParam (
            name: 'EMIT_METRICS', 
            description: 'Whether to emit metrics from the pipeline', 
            defaultValue: true)
        string (name: 'TAGGED_TESTS',
                description: 'A comma separated list of build tags for tests that should be executed (e.g. unstable_test). Default:',
                defaultValue: '',
                trim: true)
        string (name: 'INCLUDED_TESTS',
                description: 'A regex matching any fully qualified test file that should be executed (e.g. examples/helidon/). Default: .*',
                defaultValue: '.*',
                trim: true)
        string (name: 'EXCLUDED_TESTS',
                description: 'A regex matching any fully qualified test file that should not be executed (e.g. multicluster/|_excluded_test). Default: _excluded_test',
                defaultValue: '_excluded_test',
                trim: true)
    }

    environment {
        // Repositories and credentials
        GHCR_REPO = 'ghcr.io'
        OCIR_PHX_REPO = 'phx.ocir.io'
        OCR_REPO = 'container-registry.oracle.com'
        OCR_CREDS = credentials('ocr-pull-and-push-account')
        NETRC_FILE = credentials('netrc')
        GITHUB_PKGS_CREDS = credentials('github-packages-credentials-rw')
        OCIR_CREDS = credentials('ocir-pull-and-push-account')
        WEBLOGIC_PSW = credentials('weblogic-example-domain-password') // needed by install_todo.sh OAM example test
        DATABASE_PSW = credentials('todo-mysql-password') // needed by install_todo.sh OAM example test
        IMAGE_PULL_SECRET = 'verrazzano-container-registry'

        // Verrazzano variables
        TEST_ENV = "${params.TEST_ENV}"
        VZ_ENVIRONMENT_NAME = "${params.TEST_ENV == 'olcne' ? 'olcne' + env.BUILD_NUMBER : 'default'}"
        CLUSTER_NAME = 'vz-olcne'
        VERRAZZANO_OPERATOR_IMAGE="${params.VERRAZZANO_OPERATOR_IMAGE}"
        INSTALL_PROFILE = "${params.INSTALL_PROFILE}"
        GOPATH = '/home/opc/go'
        GO_REPO_PATH = "${GOPATH}/src/github.com/verrazzano"
        TEST_CONFIG_FILE = "$HOME/testConfigOke.yaml"
        KUBECONFIG = "$WORKSPACE/test_kubeconfig"
        VERRAZZANO_KUBECONFIG = "$KUBECONFIG"
        INSTALL_CONFIG_FILE_OLCNE = "$WORKSPACE/tests/e2e/config/scripts/install-verrazzano-olcne.yaml"

        // Terraform variables
        TF_VAR_tenancy_id = credentials('oci-tenancy')
        TF_VAR_compartment_id = credentials('oci-tiburon-dev-compartment-ocid')
        TF_VAR_user_id = credentials('oci-user-ocid')
        TF_VAR_fingerprint = credentials('oci-api-key-fingerprint')
        TF_VAR_api_private_key_path = credentials('oci-api-key')
        TF_VAR_region = "${params.OLCNE_CLUSTER_REGION}"
        TF_VAR_availability_domain_id = "${params.OLCNE_CLUSTER_AVAILABILITY_DOMAIN}"
        TF_VAR_deploy_networking = "true"
        TF_VAR_bastion_enabled = "true"
        TF_VAR_prefix = "vz-$TEST_ENV"
        TF_VAR_proxy = "http://www-proxy-hqdc.us.oracle.com:80"
        TF_VAR_use_vault = "false"
        TF_VAR_ssh_public_key_path = credentials('oci-tf-pub-ssh-key')
        // TODO: Figure out the private key to be used for the instances
        // TF_VAR_ssh_private_key_path = credentials('oci-tf-pvt-ssh-key')
        TF_VAR_worker_node_count = "${params.WORKER_NODE_COUNT}"
        TF_VAR_control_plane_node_count = "${params.CONTROL_PLANE_NODE_COUNT}"
        TF_VAR_os_version = "${params.OLCNE_OS_VERSION}"
        TF_VAR_environment_name = "${params.OLCNE_ENVIRONMENT_NAME}"
        TF_VAR_kubernetes_name = "${params.OLCNE_KUBERNETES_NAME}"
        TF_VAR_olcne_version = "${params.OLCNE_VERSION}"
        TF_VAR_s3_bucket_access_key = credentials('oci-s3-bucket-access-key')
        TF_VAR_s3_bucket_secret_key = credentials('oci-s3-bucket-secret-key')

        // OCI variables
        OCI_CLI_SUPPRESS_FILE_PERMISSIONS_WARNING = 'True'
        OCI_CLI_TENANCY = credentials('oci-tenancy')
        OCI_CLI_USER = credentials('oci-user-ocid')
        OCI_CLI_FINGERPRINT = credentials('oci-api-key-fingerprint')
        OCI_CLI_KEY_FILE = credentials('oci-api-key')
        // OCI_DNS_COMPARTMENT_OCID and OCI_PRIVATE_KEY_FILE are needed for setting up DNS zone in OCI
        OCI_DNS_COMPARTMENT_OCID = credentials('oci-dns-compartment')
        OCI_DNS_SCOPE = "${params.OCI_DNS_SCOPE}"
        OCI_DNS_ZONE_NAME = "${OCI_DNS_SCOPE == 'PRIVATE' ? "$OCI_DNS_ZONE_SUBDOMAIN_NAME-private.v8o.io" : "$OCI_DNS_ZONE_SUBDOMAIN_NAME.v8o.io"}"
        OCI_DNS_ZONE_SUBDOMAIN_NAME = "${dnsSubdomainName}"
        OCI_DNS_ZONE_OCID = ""

        // OLCNE variables
        OLCNE_BRANCH_TO_USE = "release/$OLCNE_VERSION"
        OLCNE_API_SERVER_IP = ""
        OLCNE_CONTROL_PLANE_NODES_IP = ""
        OLCNE_WORKER_NODES_IP = ""
        OLCNE_BASTION_OCID = ""

        // used for cluster dump
        DUMP_KUBECONFIG = "$KUBECONFIG"
        DUMP_COMMAND = "$WORKSPACE/tools/scripts/k8s-dump-cluster.sh"
        TEST_DUMP_ROOT = "$WORKSPACE/test-cluster-dumps"
        POST_DUMP_FAILED = 'false'
        POST_DUMP_FAILED_FILE = "$WORKSPACE/post_dump_failed_file.tmp"

        DISABLE_SPINNER=1
        TIMESTAMP = sh(returnStdout: true, script: "date +%Y%m%d%H%M%S").trim()
        SHORT_TIME_STAMP = sh(returnStdout: true, script: "date +%m%d%H%M%S").trim()

        // used for console artifact capture on failure
        JENKINS_READ = credentials('jenkins-auditor')
        OCI_OS_NAMESPACE = credentials('oci-os-namespace')
        OCI_OS_ARTIFACT_BUCKET = "build-failure-artifacts"
        OCI_OS_BUCKET = "verrazzano-builds"
        // OCI_COMPARTMENT_ID = credentials('oci-tiburon-dev-compartment-ocid')
        // OCI_TELEMETRY_URL = credentials('oci-telemetry-url')

        // used to emit metrics
        PROMETHEUS_GW_URL = credentials('prometheus-dev-url')
        PROMETHEUS_CREDENTIALS = credentials('prometheus-credentials')
        TEST_ENV_LABEL = "${params.TEST_ENV}"
        SEARCH_HTTP_ENDPOINT = credentials('search-gw-url')
        SEARCH_PASSWORD = "$PROMETHEUS_CREDENTIALS_PSW"
        SEARCH_USERNAME = "$PROMETHEUS_CREDENTIALS_USR"

        // used to generate Ginkgo test reports
        TEST_REPORT = "test-report.xml"
        GINKGO_REPORT_ARGS = "--junit-report=${TEST_REPORT} --keep-separate-reports=true"
    }

    stages {
        stage("Create OCI Storage") {
            steps {
                script {
                    echo "[INFO] Creating OCI FileSystem"
                    createOCIFileSystem()
                }
            }
        }


        stage("Create OCI Load Balancers") {
            steps {
                script {
                    echo "[INFO] Creating OCI LoadBalancers"
                    createOCILoadBalancers()
                }
            }
        }

       stage("Create OCI DNS zone") {
            environment {
                TF_VAR_prefix = "$OLCNE_CLUSTER_PREFIX"
            }
            steps {
                script {
                    echo "[INFO] Creating OCI DNS Zone"
                    createOCIDNSZone()
                }
            }
        }

        stage("Create image pull secrets") {
            steps {
                script {
                    echo "[INFO] Creating image pull secrets"
                    createImagePullSecrets()
                }
            }
        }
    }
    post {
        always {
            script {
                if (keepOLCNEClusterOnFailure == false) {
                    echo "[INFO] Deleting OLCNE Cluster"
                    deleteOLCNECluster()
                    echo "[INFO] Deleting OCI DNS Zone"
                    deleteOCIDNSZone()
                    echo "[INFO] Deleting OCI FileSystem"
                    deleteOCIFileSystem()
                    echo "[INFO] Deleting OCI LoadBalancers"
                    deleteOCILoadBalancers()
                }
            }
        }
    }
}

def generateNonWLSAcceptanceTestStages(dumpRoot, skipDeploy = 'false', skipUndeploy = 'false') {
    return generate_security_tests(dumpRoot) + generate_nonwls_tests(dumpRoot, skipDeploy, skipUndeploy)
}

def generateAllAcceptanceTestStages(dumpRoot, skipDeploy = 'false', skipUndeploy = 'false') {
    return generate_security_tests(dumpRoot) +
        generate_nonwls_tests(dumpRoot, skipDeploy, skipUndeploy) +
        generate_wls_tests(dumpRoot, skipDeploy, skipUndeploy)
}

def generateVerifyInfraStages(dumpRoot) {
    return [
        "verify-scripts": {
            runGinkgo('scripts', '', "$KUBECONFIG")
        },
        "verify-infra restapi": {
            runGinkgoRandomize('verify-infra/restapi', "${dumpRoot}/verify-infra-restapi")
        },
        "verify-infra oam": {
            runGinkgoRandomize('verify-infra/oam', "${dumpRoot}/verify-infra-oam")
        },
        "system component metrics": {
            runGinkgoRandomize('metrics/syscomponents', "${dumpRoot}/system-component-metrics")
        },
        "console": {
            acceptanceTestsConsole("${dumpRoot}")
        },
    ]
}

def generate_security_tests(dumpRoot) {
    return [
        "istio authorization policy": {
            runGinkgo('istio/authz', "${dumpRoot}/istio-authz-policy")
        },
        "security role based access": {
            runGinkgo('security/rbac', "${dumpRoot}/sec-role-based-access")
        },
        "security network policies": {
            if (params.CREATE_CLUSTER_USE_CALICO == true) {
                runGinkgo('security/netpol', "${dumpRoot}/netpol")
            } else {
                echo "[INFO] Calico not enabled, skipping network policies tests"
            }
        },
    ]
}

def generate_nonwls_tests(dumpRoot, skipDeploy = 'false', skipUndeploy = 'false') {
    return [
        "k8s deployment workload metrics": {
            runGinkgo('metrics/deploymetrics', "${dumpRoot}/k8sdeploy-workload-metrics")
        },
        "examples logging helidon": {
            runGinkgo('logging/helidon', "${dumpRoot}/examples-logging-helidon")
        },
        "examples spring": {
            runGinkgoAppTest('examples/springboot', "springboot", "${dumpRoot}/examples-spring", skipDeploy, skipUndeploy)
        },
        "examples helidon": {
            runGinkgoAppTest('examples/helidon', "hello-helidon", "${dumpRoot}/examples-helidon", skipDeploy, skipUndeploy)
        },
        "examples helidon-config": {
            runGinkgoAppTest('examples/helidonconfig', "helidon-config", "${dumpRoot}/examples-helidon-config", skipDeploy, skipUndeploy)
        },
    ]
}

def generate_wls_tests(dumpRoot, skipDeploy = 'false', skipUndeploy = 'false') {
    return [
        "weblogic workload": {
            runGinkgoAppTest('workloads/weblogic', "hello-wls", "${dumpRoot}/weblogic-workload", skipDeploy, skipUndeploy)
        },
        "coherence workload": {
            runGinkgoAppTest('workloads/coherence', "hello-coherence", "${dumpRoot}/coherence-workload", skipDeploy, skipUndeploy)
        },
        "console ingress": {
            // doesn't work with the deployement hooks
            runGinkgo('ingress/console', "wls-console", "${dumpRoot}/console-ingress")
        },
    ]
}

// Called in parallel Stage console of Stage Run Acceptance Tests
def acceptanceTestsConsole(dumpRoot) {
    try {
        sh "CONSOLE_REPO_BRANCH=${params.CONSOLE_REPO_BRANCH} $WORKSPACE/ci/scripts/run_console_tests.sh"
    } catch (err) {
        saveConsoleScreenShots()
        error "${err}"
    }
}

def saveConsoleScreenShots() {
    sh "$WORKSPACE/ci/scripts/save_console_test_artifacts.sh"
}

def getTestClusterType(testEnv) {
    if("kind".equalsIgnoreCase(testEnv)) {
        return "KIND"
    } else {
        return "OKE"
    }
}

def runGinkgoRandomize(testSuitePath, dumpDir = '') {
    catchError(buildResult: 'FAILURE', stageResult: 'FAILURE') {
        sh """
            if [ ! -z "${dumpDir}" ]; then
                export DUMP_DIRECTORY=${dumpDir}
            fi
            cd $WORKSPACE/tests/e2e
            ginkgo -p --randomize-all -v --keep-going --no-color ${GINKGO_REPORT_ARGS} -tags="${params.TAGGED_TESTS}" --focus-file="${params.INCLUDED_TESTS}" --skip-file="${params.EXCLUDED_TESTS}" ${testSuitePath}/...
        """
    }
}

def runGinkgo(testSuitePath, dumpDir = '', kubeconfig = '') {
    catchError(buildResult: 'FAILURE', stageResult: 'FAILURE') {
        sh """
            if [ ! -z "${dumpDir}" ]; then
                export DUMP_DIRECTORY=${dumpDir}
            fi
            if [ ! -z "$kubeConfig" ]; then
                export KUBECONFIG="$kubeConfig"
            fi
            cd $WORKSPACE/tests/e2e
            ginkgo -v --keep-going --no-color ${GINKGO_REPORT_ARGS} -tags="${params.TAGGED_TESTS}" --focus-file="${params.INCLUDED_TESTS}" --skip-file="${params.EXCLUDED_TESTS}" ${testSuitePath}/...
        """
    }
}

def runGinkgoFailFast(testSuitePath, dumpDir = '') {
    catchError(buildResult: 'FAILURE', stageResult: 'FAILURE') {
        sh """
            if [! -z "${dumpDir}" ]; then
                export DUMP_DIRECTORY=${dumpDir}
            fi 
            cd $WORKSPACE/tests/e2e
            ginkgo -v --fail-fast --no-color ${GINKGO_REPORT_ARGS} -tags="${params.TAGGED_TESTS}" --focus-file="${params.INCLUDED_TESTS}" --skip-file="${params.EXCLUDED_TESTS}" ${testSuitePath}/...
        """
    }
}

def runGinkgoAppTest(testSuitePath, namespace, dumpDir = '', skipDeploy = 'false', skipUndeploy = 'false') {
    catchError(buildResult: 'FAILURE', stageResult: 'FAILURE') {
        sh """
            if [ ! -z "${dumpDir}" ]; then
                export DUMP_DIRECTORY=${dumpDir}
            fi
            cd $WORKSPACE/tests/e2e
            ginkgo -v --keep-going --no-color ${GINKGO_REPORT_ARGS} -tags="${params.TAGGED_TESTS}" --focus-file="${params.INCLUDED_TESTS}" --skip-file="${params.EXCLUDED_TESTS}" ${testSuitePath}/... -- --skipDeploy=${skipDeploy} --skipUndeploy=${skipUndeploy} --namespace=${namespace}
        """
    }
}

def dumpK8sCluster(dumpDirectory) {
    sh """
        $WORKSPACE/tools/scripts/k8s-dump-cluster.sh -d ${dumpDirectory} -r ${dumpDirectory}/cluster-dump/analysis.report
    """
}

def dumpVerrazzanoSystemPods() {
    sh """
        export DIAGNOSTIC_LOG="$WORKSPACE/platform-operator/scripts/install/build/logs/verrazzano-system-pods.log"
        $WORKSPACE/platform-operator/scripts/install/k8s-dump-objects.sh -o pods -n verrazzano-system -m "verrazzano system pods" || echo "[ERROR] failed" > ${POST_DUMP_FAILED_FILE}
        export DIAGNOSTIC_LOG="$WORKSPACE/platform-operator/scripts/install/build/logs/verrazzano-system-certs.log"
        $WORKSPACE/platform-operator/scripts/install/k8s-dump-objects.sh -o cert -n verrazzano-system -m "verrazzano system certs" || echo "[ERROR] failed" > ${POST_DUMP_FAILED_FILE}
        export DIAGNOSTIC_LOG="$WORKSPACE/platform-operator/scripts/install/build/logs/verrazzano-system-kibana.log"
        $WORKSPACE/platform-operator/scripts/install/k8s-dump-objects.sh -o pods -n verrazzano-system -r "vmi-system-kibana-*" -m "verrazzano system kibana log" -l -c kibana || echo "[ERROR] failed" > ${POST_DUMP_FAILED_FILE}
        export DIAGNOSTIC_LOG="$WORKSPACE/platform-operator/scripts/install/build/logs/verrazzano-system-es-master.log"
        $WORKSPACE/platform-operator/scripts/install/k8s-dump-objects.sh -o pods -n verrazzano-system -r "vmi-system-es-master-*" -m "verrazzano system kibana log" -l -c es-master || echo "[ERROR] failed" > ${POST_DUMP_FAILED_FILE}
    """
}

def dumpCertManagerNamespaceLogs() {
    sh """
        kubectl logs --selector=app=cert-manager -n cert-manager > $WORKSPACE/platform-operator/scripts/install/build/logs/cert-manager.log || echo "[ERROR] failed" > ${POST_DUMP_FAILED_FILE}
        kubectl logs --selector=app.kubernetes.io/name=external-dns -n cert-manager > $WORKSPACE/platform-operator/scripts/install/build/logs/external-dns.log || echo "[ERROR] failed" > ${POST_DUMP_FAILED_FILE}
    """
}

def dumpCattleSystemPods() {
    sh """
        export DIAGNOSTIC_LOG="$WORKSPACE/platform-operator/scripts/install/build/logs/cattle-system-pods.log"
        $WORKSPACE/platform-operator/scripts/install/k8s-dump-objects.sh -o pods -n cattle-system -m "cattle system pods" || echo "[ERROR] failed" > ${POST_DUMP_FAILED_FILE}
        export DIAGNOSTIC_LOG="$WORKSPACE/platform-operator/scripts/install/build/logs/rancher.log"
        $WORKSPACE/platform-operator/scripts/install/k8s-dump-objects.sh -o pods -n cattle-system -r "rancher-*" -m "Rancher logs" -c rancher -l || echo "[ERROR] failed" > ${POST_DUMP_FAILED_FILE}
    """
}

def dumpNginxIngressControllerLogs() {
    sh """
        export DIAGNOSTIC_LOG="$WORKSPACE/platform-operator/scripts/install/build/logs/nginx-ingress-controller.log"
        $WORKSPACE/platform-operator/scripts/install/k8s-dump-objects.sh -o pods -n ingress-nginx -r "nginx-ingress-controller-*" -m "Nginx Ingress Controller" -c controller -l || echo "[ERROR] failed" > ${POST_DUMP_FAILED_FILE}
    """
}

def dumpVerrazzanoPlatformOperatorLogs() {
    sh """
        ## dump out verrazzano-platform-operator logs
        mkdir -p $WORKSPACE/verrazzano-platform-operator/logs
        kubectl -n verrazzano-install logs --selector=app=verrazzano-platform-operator > $WORKSPACE/verrazzano-platform-operator/logs/verrazzano-platform-operator-pod.log --tail -1 || echo "[ERROR] failed" > ${POST_DUMP_FAILED_FILE}
        kubectl -n verrazzano-install describe pod --selector=app=verrazzano-platform-operator > $WORKSPACE/verrazzano-platform-operator/logs/verrazzano-platform-operator-pod.out || echo "[ERROR] failed" > ${POST_DUMP_FAILED_FILE}
        echo "[INFO] verrazzano-platform-operator logs dumped to verrazzano-platform-operator-pod.log"
        echo "[INFO] verrazzano-platform-operator pod description dumped to verrazzano-platform-operator-pod.out"
        echo "[INFO] ------------------------------------------"
    """
}

def dumpVerrazzanoApplicationOperatorLogs() {
    sh """
        ## dump out verrazzano-application-operator logs
        mkdir -p $WORKSPACE/verrazzano-application-operator/logs
        kubectl -n verrazzano-system logs --selector=app=verrazzano-application-operator > $WORKSPACE/verrazzano-application-operator/logs/verrazzano-application-operator-pod.log --tail -1 || echo "[ERROR] failed" > ${POST_DUMP_FAILED_FILE}
        kubectl -n verrazzano-system describe pod --selector=app=verrazzano-application-operator > $WORKSPACE/verrazzano-application-operator/logs/verrazzano-application-operator-pod.out || echo "[ERROR] failed" > ${POST_DUMP_FAILED_FILE}
        echo "[INFO] verrazzano-application-operator logs dumped to verrazzano-application-operator-pod.log"
        echo "[INFO] verrazzano-application-operator pod description dumped to verrazzano-application-operator-pod.out"
        echo "[INFO] ------------------------------------------"
    """
}

def dumpVerrazzanoApiLogs() {
    sh """
        export DIAGNOSTIC_LOG="$WORKSPACE/platform-operator/scripts/install/build/logs/verrazzano-authproxy.log"
        $WORKSPACE/platform-operator/scripts/install/k8s-dump-objects.sh -o pods -n verrazzano-system -r "verrazzano-authproxy-*" -m "verrazzano api" -c verrazzano-authproxy -l || echo "[ERROR] failed" > ${POST_DUMP_FAILED_FILE}
    """
}

def getEffectiveDumpOnSuccess() {
    def effectiveValue = params.DUMP_K8S_CLUSTER_ON_SUCCESS
    if (FORCE_DUMP_K8S_CLUSTER_ON_SUCCESS.equals("true") && (env.BRANCH_NAME.equals("master"))) {
        effectiveValue = true
        echo "[INFO] Forcing dump on success based on global override setting"
    }
    return effectiveValue
}

def metricJobName(stageName) {
    job = env.JOB_NAME.split("/")[0]
    job = '_' + job.replaceAll('-','_')
    if (stageName) {
        job = job + '_' + stageName
    }
    return job
}

// Construct the set of labels/dimensions for the metrics
def getMetricLabels() {
    def buildNumber = String.format("%010d", env.BUILD_NUMBER.toInteger())
    labels = 'build_number=\\"' + "${buildNumber}"+'\\",' +
             'jenkins_build_number=\\"' + "${env.BUILD_NUMBER}"+'\\",' +
             'jenkins_job=\\"' + "${env.JOB_NAME}".replace("%2F","/") + '\\",' +
             'commit_sha=\\"' + "${env.GIT_COMMIT}"+'\\",' +
             'kubernetes_version=\\"' + "${params.K8S_VERSION}"+'\\",' +
             'test_env=\\"' + "ocidns_oke"+'\\"'
    return labels
}

def metricTimerStart(metricName) {
    def timerStartName = "${metricName}_START"
    env."${timerStartName}" = sh(returnStdout: true, script: "date +%s").trim()
}

def metricTimerEnd(metricName, status) {
    def timerStartName = "${metricName}_START"
    def timerEndName   = "${metricName}_END"
    env."${timerEndName}" = sh(returnStdout: true, script: "date +%s").trim()
    if (params.EMIT_METRICS) {
        long x = env."${timerStartName}" as long;
        long y = env."${timerEndName}" as long;
        def dur = (y-x)

        // OCI-Telemetry
        // labels = '\\"number\\"=\\"' + "${env.BUILD_NUMBER}"+'\\",' +
        //          '\\"commit_sha\\"=\\"' + "${env.GIT_COMMIT}"+'\\",' +
        //          '\\"test_env\\"=\\"' + "$testEnv"+'\\"'
        // OCI_MET=sh(returnStdout: true, script: "ci/scripts/oci_metric_emit.sh ${OCI_TELEMETRY_URL} ${OCI_COMPARTMENT_ID} ${OCI_METRICS_NAMESPACE} ${metricName} ${env.BRANCH_NAME} $labels ${status} ${dur}")

        labels = getMetricLabels()
        withCredentials([usernameColonPassword(credentialsId: 'prometheus-credentials', variable: 'PROMETHEUS_CREDENTIALS')]) {
            EMIT = sh(returnStdout: true, script: "ci/scripts/metric_emit.sh ${PROMETHEUS_GW_URL} ${PROMETHEUS_CREDENTIALS} ${metricName} ${env.BRANCH_NAME} $labels ${status} ${dur}")
            echo "[INFO] emit prometheus metrics: $EMIT"
            return EMIT
        }
    } else {
        return ''
    }
}

// Emit the metrics indicating the duration and result of the build
def metricBuildDuration() {
    def status = "${currentBuild.currentResult}".trim()
    long duration = "${currentBuild.duration}" as long;
    long durationInSec = (duration/1000)
    testMetric = metricJobName('')
    def metricValue = "-1"
    statusLabel = status.substring(0,1)
    if (status.equals("SUCCESS")) {
        metricValue = "1"
    } else if (status.equals("FAILURE")) {
        metricValue = "0"
    } else {
        // Consider every other status as a single label
        statusLabel = "A"
    }
    if (params.EMIT_METRICS) {
        labels = getMetricLabels()
        labels = labels + ',result=\\"' + "${statusLabel}"+'\\"'
        withCredentials([usernameColonPassword(credentialsId: 'prometheus-credentials', variable: 'PROMETHEUS_CREDENTIALS')]) {
            METRIC_STATUS = sh(returnStdout: true, returnStatus: true, script: "ci/scripts/metric_emit.sh ${PROMETHEUS_GW_URL} ${PROMETHEUS_CREDENTIALS} ${testMetric}_job ${env.BRANCH_NAME} $labels ${metricValue} ${durationInSec}")
            echo "[INFO] Publishing the metrics for build duration and status returned status code $METRIC_STATUS"
        }
    }
}


def setDisplayName() {
    echo "[INFO] Start setDisplayName"
    def causes = currentBuild.getBuildCauses()
    echo "[INFO] causes: " + causes.toString()
    for (cause in causes) {
        def causeString = cause.toString()
        echo "[INFO] current cause: " + causeString
        if (causeString.contains("UpstreamCause") && causeString.contains("Started by upstream project")) {
             echo "[INFO] This job was caused by " + causeString
             if (causeString.contains("verrazzano-periodic-triggered-tests")) {
                 currentBuild.displayName = env.BUILD_NUMBER + " : PERIODIC"
             } else if (causeString.contains("verrazzano-flaky-tests")) {
                 currentBuild.displayName = env.BUILD_NUMBER + " : FLAKY"
             }
         }
    }
    echo "[INFO] End setDisplayName"
}

def createImagePullSecrets() {
    sh """
        # Create image pull secrets for Verrazzano docker images
        cd $WORKSPACE
        $WORKSPACE/tests/e2e/config/scripts/create-image-pull-secret.sh "${IMAGE_PULL_SECRET}" "${GHCR_REPO}" "${GITHUB_PKGS_CREDS_USR}" "${GITHUB_PKGS_CREDS_PSW}"
        $WORKSPACE/tests/e2e/config/scripts/create-image-pull-secret.sh github-packages "${GHCR_REPO}" "${GITHUB_PKGS_CREDS_USR}" "${GITHUB_PKGS_CREDS_PSW}"
        $WORKSPACE/tests/e2e/config/scripts/create-image-pull-secret.sh ocr "${OCR_REPO}" "${OCR_CREDS_USR}" "${OCR_CREDS_PSW}"
    """
}

def emitJobMetrics() {
    env.JOB_STATUS = "${currentBuild.currentResult}".trim()
    long duration = "${currentBuild.duration}" as long;
    env.DURATION = duration
    long timeInMillis = "${currentBuild.timeInMillis}" as long;
    long startTimeInMillis = "${currentBuild.startTimeInMillis}" as long;
    env.TIME_WAITING = startTimeInMillis-timeInMillis
    runGinkgo('jobmetrics')
}

def runVerrazzanoAcceptanceTests() {
    return [
        'metrics': stage('metrics') {
            steps {
                runGinkgo('metrics/syscomponents', "${TEST_DUMP_ROOT}/syscomponents-metrics")
            }
        },
        'restapi': stage('restapi') {
            steps {
                runGinkgo('verify-infra/restapi', "${TEST_DUMP_ROOT}/restapi-infra")
            }
        },
        'vmi': stage('vmi') {
            steps {
                runGinkgo('verify-infra/vmi', "${TEST_DUMP_ROOT}/vmi-infra")
            }
        },
        'oam': stage('oam') {
            steps {
                runGinkgo('verify-infra/oam', "${TEST_DUMP_ROOT}/oam-infra")
            }
        },
        'system-logging': stage('system-logging') {
            steps {
                runGinkgo('logging/system', "${TEST_DUMP_ROOT}/system-logging")
            }
        },
        'istio-authorization-policy': stage('istio-authorization-policy') {
            steps {
                runGinkgo('istio/authz', "${TEST_DUMP_ROOT}/examples-istio-auth-policy")
            }
        },
        'security-role-based-access': stage('security-role-based-access') {
            steps {
                runGinkgo('security/rbac', "${TEST_DUMP_ROOT}/examples-rbac")
            }
        },
        'WebLogic-logging': stage('WebLogic-logging') {
            steps {
                runGinkgoFailFast('logging/weblogic', "${TEST_DUMP_ROOT}/weblogic-logging")
            }
        },
        'helidon-workload': stage('helidon-workload') {
            steps {
                runGinkgoFailFast('examples/helidon', "${TEST_DUMP_ROOT}/helidon-workload")
            }
        },
        'weblogic-workload': stage('weblogic-workload') {
            steps {
                runGinkgoFailFast('workloads/weblogic', "${TEST_DUMP_ROOT}/weblogic-workload")
            }
        },
        'coherence-workload': stage('coherence-workload') {
            steps {
                runGinkgoFailFast('workloads/coherence', "${TEST_DUMP_ROOT}/coherence-workload")
            }
        }
    ]
}

def createOCIFileSystem() {
    sh """
        $WORKSPACE/tests/e2e/config/scripts/oci_fs_ops.sh \
        -o "create" -a $TF_VAR_availability_domain_id \
        -n "$TF_VAR_prefix-fs" -m "$TF_VAR_prefix-mt" \
        -p "/$TF_VAR_prefix-export" -c $TF_VAR_compartment_id -s $PRIVATE_SUBNET_OCID
    """
}

def deleteOCIFileSystem() {
    sh """
        $WORKSPACE/tests/e2e/config/scripts/oci_fs_ops.sh \
        -o "delete" -a $TF_VAR_availability_domain_id \
        -n "$TF_VAR_prefix-fs" -m "$TF_VAR_prefix-mt" \
        -p "/$TF_VAR_prefix-export" -c $TF_VAR_compartment_id
    """
}

def createOCILoadBalancers() {
    sh """
        $WORKSPACE/tests/e2e/config/scripts/oci_lb_ops.sh \
        -o "create" -n "$TF_VAR_prefix-mgnmt" -e "true" \
        -c $TF_VAR_compartment_id -s $PUBLIC_SUBNET_OCID \
        -i $WORKER_NODES_IP -p 30443 \
        -f "$WORKSPACE/ci/olcne/load-balancer.json"

        $WORKSPACE/tests/e2e/config/scripts/oci_lb_ops.sh \
        -o "create" -n "$TF_VAR_prefix-app" -e "true" \
        -c $TF_VAR_compartment_id -s $PUBLIC_SUBNET_OCID \
        -i $WORKER_NODES_IP -p 31390 \
        -f "$WORKSPACE/ci/olcne/load-balancer.json"
    """
}

def deleteOCILoadBalancers() {
    sh """
        $WORKSPACE/tests/e2e/config/scripts/oci_lb_ops.sh \
        -o delete -n "$TF_VAR_prefix-mgnmt" \
        -c $TF_VAR_compartment_id

        $WORKSPACE/tests/e2e/config/scripts/oci_lb_ops.sh \
        -o delete -n "$TF_VAR_prefix-app" \
        -c $TF_VAR_compartment_id
    """
}

def createOCIDNSZone() {
    script {
        if (env.OCI_DNS_SCOPE == "PRIVATE") {
        switch(env.TF_VAR_region) {
            case "uk-london-1":
                env.VCN_VIEW_ID = "$DNS_VIEW_FOR_PRIVATE_DNS_LHR"
                break
            default:
                env.VCN_VIEW_ID = "$DNS_VIEW_FOR_PRIVATE_DNS_PHX"
                break
            }
            echo "[INFO] VCN View ID is ${env.VCN_VIEW_ID}"
        }
        // VCN_VIEW_ID is used inside oci_dns_ops.sh to associate private zones to view
        // this is only used when zone is PRIVATE
        dnsZoneOCID = sh(script: "$WORKSPACE/tests/e2e/config/scripts/oci_dns_ops.sh -o create -c $TF_VAR_compartment_id -s $OCI_DNS_ZONE_SUBDOMAIN_NAME -k $OCI_DNS_SCOPE", returnStdout: true)
    }
}

def deleteOCIDNSZone() {
    sh """
        $WORKSPACE/tests/e2e/config/scripts/oci_dns_ops.sh \
        -o delete -s $OCI_DNS_ZONE_SUBDOMAIN_NAME -k $OCI_DNS_SCOPE \
        || echo "[ERROR] Failed to delete DNS zone $OCI_DNS_ZONE_SUBDOMAIN_NAME"
    """
}

// TODO: Run terraform to create the OLCNE cluster
def createOLCNECluster() {
    sh"""
    """
}

// TODO: Run terraform delete to remove the OLCNE cluster
def deleteOLCNECluster() {
    sh """
    """
}


def installVerrazzanoPlatformOperator() {
    sh """
        oci --region us-phoenix-1 os object get \
        --namespace $OCI_OS_NAMESPACE -bn $OCI_OS_BUCKET \
        --name ${env.BRANCH_NAME}/$SHORT_COMMIT_HASH/operator.yaml \
        --file $WORKSPACE/downloaded-operator.yaml
        cp $WORKSPACE/downloaded-operator.yaml $WORKSPACE/acceptance-test-operator.yaml
        # Install the verrazzano-platform-operator
        kubectl apply -f $WORKSPACE/acceptance-test-operator.yaml
        # make sure ns exists
        $WORKSPACE/tests/e2e/config/scripts/check_verrazzano_ns_exists.sh verrazzano-install
        # create secret in verrazzano-install ns
        $WORKSPACE/tests/e2e/config/scripts/create-image-pull-secret.sh "$IMAGE_PULL_SECRET" "$GHCR_REPO" "$GITHUB_PKGS_CREDS_USR" "$GITHUB_PKGS_CREDS_PSW" "verrazzano-install"
    """
}

def installVerrazzano() {
    sh """
        kubectl -n verrazzano-install rollout status deployment/verrazzano-platform-operator
        # apply config to create cluster
        kubectl apply -f $INSTALL_CONFIG_FILE_OLCNE
        # wait for Verrazzano install to complete
        $WORKSPACE/tests/e2e/config/scripts/wait-for-verrazzano-install.sh
        # Create acceptance test configuration file
        $WORKSPACE/tests/e2e/config/scripts/common-test-setup-script.sh "$WORKSPACE" "$TEST_CONFIG_FILE" "$GHCR_REPO" "$KUBECONFIG" "$OCR_CREDS_USR" "$OCR_CREDS_PSW" "$VZ_ENVIRONMENT_NAME"
        # TODO: edit the test config file
        $WORKSPACE/tests/e2e/config/scripts/get_ingress_ip.sh $TEST_CONFIG_FILE
        echo "[INFO] ----------Test config file:-------------"
        cat $TEST_CONFIG_FILE
        echo "[INFO] ----------------------------------------"   
    """
}

def dumpVerrazzanoInstallLogs() {
    sh """
        ## dump out install logs
        mkdir -p $WORKSPACE/platform-operator/scripts/install/build/logs
        kubectl -n verrazzano-install logs --selector=job-name=verrazzano-install-my-verrazzano > $WORKSPACE/platform-operator/scripts/install/build/logs/verrazzano-install.log --tail -1
        kubectl -n verrazzano-install describe pod --selector=job-name=verrazzano-install-my-verrazzano > $WORKSPACE/platform-operator/scripts/install/build/logs/verrazzano-install-job-pod.out
        echo "[INFO] Verrazzano Installation logs dumped to verrazzano-install.log"
        echo "[INFO] Verrazzano Install pod description dumped to verrazzano-install-job-pod.out"
        echo "[INFO] ------------------------------------------"
    """
}
